{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import os \n",
    "import warnings\n",
    "from patsy import dmatrices\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from pylab import rcParams\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33926, 94)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('D:/FV_Raw/S01_05_rev.csv')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.704672</td>\n",
       "      <td>0.569560</td>\n",
       "      <td>0.478011</td>\n",
       "      <td>0.3787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.613485</td>\n",
       "      <td>0.783795</td>\n",
       "      <td>0.783795</td>\n",
       "      <td>0.369048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085822</td>\n",
       "      <td>0.033478</td>\n",
       "      <td>0.085538</td>\n",
       "      <td>0.058413</td>\n",
       "      <td>0.030419</td>\n",
       "      <td>0.710969</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497083</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.276039</td>\n",
       "      <td>0.431766</td>\n",
       "      <td>0.325844</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.489699</td>\n",
       "      <td>0.446879</td>\n",
       "      <td>0.446879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100576</td>\n",
       "      <td>0.020811</td>\n",
       "      <td>0.075046</td>\n",
       "      <td>0.063253</td>\n",
       "      <td>0.032340</td>\n",
       "      <td>0.780613</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.180883</td>\n",
       "      <td>0.306293</td>\n",
       "      <td>0.247769</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.376979</td>\n",
       "      <td>0.391897</td>\n",
       "      <td>0.247210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118208</td>\n",
       "      <td>0.156714</td>\n",
       "      <td>0.223768</td>\n",
       "      <td>0.065391</td>\n",
       "      <td>0.115917</td>\n",
       "      <td>0.247516</td>\n",
       "      <td>0.01976</td>\n",
       "      <td>0.023164</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.227390</td>\n",
       "      <td>0.350265</td>\n",
       "      <td>0.270236</td>\n",
       "      <td>0.7901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416482</td>\n",
       "      <td>0.391897</td>\n",
       "      <td>0.326788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091400</td>\n",
       "      <td>0.066051</td>\n",
       "      <td>0.151460</td>\n",
       "      <td>0.039167</td>\n",
       "      <td>0.049621</td>\n",
       "      <td>0.587263</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.161380</td>\n",
       "      <td>0.293215</td>\n",
       "      <td>0.247769</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.365231</td>\n",
       "      <td>0.326788</td>\n",
       "      <td>0.326788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005578</td>\n",
       "      <td>0.014296</td>\n",
       "      <td>0.019389</td>\n",
       "      <td>0.035678</td>\n",
       "      <td>0.002729</td>\n",
       "      <td>0.969047</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497083</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2       3    4         5         6         7  \\\n",
       "0  0.704672  0.569560  0.478011  0.3787  0.0  0.613485  0.783795  0.783795   \n",
       "1  0.276039  0.431766  0.325844  0.7500  0.0  0.489699  0.446879  0.446879   \n",
       "2  0.180883  0.306293  0.247769  0.7500  0.0  0.376979  0.391897  0.247210   \n",
       "3  0.227390  0.350265  0.270236  0.7901  0.0  0.416482  0.391897  0.326788   \n",
       "4  0.161380  0.293215  0.247769  0.6875  0.0  0.365231  0.326788  0.326788   \n",
       "\n",
       "          8    9  ...        79        80        81        82        83  \\\n",
       "0  0.369048  0.0  ...  0.085822  0.033478  0.085538  0.058413  0.030419   \n",
       "1  0.000000  0.0  ...  0.100576  0.020811  0.075046  0.063253  0.032340   \n",
       "2  0.000000  0.0  ...  0.118208  0.156714  0.223768  0.065391  0.115917   \n",
       "3  0.000000  0.0  ...  0.091400  0.066051  0.151460  0.039167  0.049621   \n",
       "4  0.000000  0.0  ...  0.005578  0.014296  0.019389  0.035678  0.002729   \n",
       "\n",
       "         84       85        86        87  Class  \n",
       "0  0.710969  0.00000  0.000000  0.497083     17  \n",
       "1  0.780613  0.00000  0.003934  1.000000     21  \n",
       "2  0.247516  0.01976  0.023164  1.000000      9  \n",
       "3  0.587263  0.00000  0.002404  1.000000     21  \n",
       "4  0.969047  0.00000  0.000000  0.497083      9  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = data.drop(['L0t','Class','S_NO','D_ID','FV89','FV90'], axis=1)\n",
    "target = data['Class']\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "data2_norm=min_max_scaler.fit_transform(var)\n",
    "data2_norm = pd.DataFrame(data2_norm)\n",
    "data_norm = data2_norm.merge(target.to_frame(),left_index=True, right_index = True)\n",
    "data_norm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.240235</td>\n",
       "      <td>-1.169858</td>\n",
       "      <td>0.663074</td>\n",
       "      <td>0.019229</td>\n",
       "      <td>0.620195</td>\n",
       "      <td>-0.742148</td>\n",
       "      <td>0.348154</td>\n",
       "      <td>-0.373015</td>\n",
       "      <td>-0.075575</td>\n",
       "      <td>-0.128976</td>\n",
       "      <td>-0.275285</td>\n",
       "      <td>0.310400</td>\n",
       "      <td>0.193656</td>\n",
       "      <td>-0.047904</td>\n",
       "      <td>-0.133225</td>\n",
       "      <td>0.149162</td>\n",
       "      <td>0.080341</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.225106</td>\n",
       "      <td>-0.629123</td>\n",
       "      <td>-0.091924</td>\n",
       "      <td>-0.062670</td>\n",
       "      <td>-0.266067</td>\n",
       "      <td>0.186320</td>\n",
       "      <td>0.080216</td>\n",
       "      <td>-0.201968</td>\n",
       "      <td>0.101115</td>\n",
       "      <td>0.224332</td>\n",
       "      <td>0.061510</td>\n",
       "      <td>-0.096633</td>\n",
       "      <td>0.261985</td>\n",
       "      <td>-0.049817</td>\n",
       "      <td>-0.064037</td>\n",
       "      <td>-0.040096</td>\n",
       "      <td>0.147393</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.190383</td>\n",
       "      <td>-0.517377</td>\n",
       "      <td>-0.379907</td>\n",
       "      <td>0.399697</td>\n",
       "      <td>-0.603177</td>\n",
       "      <td>-0.109152</td>\n",
       "      <td>0.063760</td>\n",
       "      <td>-0.082697</td>\n",
       "      <td>0.496658</td>\n",
       "      <td>-0.146083</td>\n",
       "      <td>0.055157</td>\n",
       "      <td>-0.007380</td>\n",
       "      <td>-0.086956</td>\n",
       "      <td>0.069441</td>\n",
       "      <td>0.175715</td>\n",
       "      <td>-0.045392</td>\n",
       "      <td>-0.197643</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.363851</td>\n",
       "      <td>-0.501417</td>\n",
       "      <td>-0.156138</td>\n",
       "      <td>-0.177678</td>\n",
       "      <td>0.142810</td>\n",
       "      <td>-0.444388</td>\n",
       "      <td>-0.358293</td>\n",
       "      <td>0.082453</td>\n",
       "      <td>0.159960</td>\n",
       "      <td>-0.063044</td>\n",
       "      <td>0.104709</td>\n",
       "      <td>0.137652</td>\n",
       "      <td>-0.010886</td>\n",
       "      <td>0.114063</td>\n",
       "      <td>0.020326</td>\n",
       "      <td>-0.067436</td>\n",
       "      <td>-0.050562</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.802729</td>\n",
       "      <td>-0.378539</td>\n",
       "      <td>-0.345526</td>\n",
       "      <td>-0.114439</td>\n",
       "      <td>0.687051</td>\n",
       "      <td>-0.119308</td>\n",
       "      <td>0.034842</td>\n",
       "      <td>0.214920</td>\n",
       "      <td>-0.087094</td>\n",
       "      <td>0.053155</td>\n",
       "      <td>-0.046394</td>\n",
       "      <td>-0.264762</td>\n",
       "      <td>0.115810</td>\n",
       "      <td>0.272997</td>\n",
       "      <td>-0.048212</td>\n",
       "      <td>0.042004</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.240235 -1.169858  0.663074  0.019229  0.620195 -0.742148  0.348154   \n",
       "1 -0.225106 -0.629123 -0.091924 -0.062670 -0.266067  0.186320  0.080216   \n",
       "2 -0.190383 -0.517377 -0.379907  0.399697 -0.603177 -0.109152  0.063760   \n",
       "3 -0.363851 -0.501417 -0.156138 -0.177678  0.142810 -0.444388 -0.358293   \n",
       "4 -0.802729 -0.378539 -0.345526 -0.114439  0.687051 -0.119308  0.034842   \n",
       "\n",
       "          7         8         9        10        11        12        13  \\\n",
       "0 -0.373015 -0.075575 -0.128976 -0.275285  0.310400  0.193656 -0.047904   \n",
       "1 -0.201968  0.101115  0.224332  0.061510 -0.096633  0.261985 -0.049817   \n",
       "2 -0.082697  0.496658 -0.146083  0.055157 -0.007380 -0.086956  0.069441   \n",
       "3  0.082453  0.159960 -0.063044  0.104709  0.137652 -0.010886  0.114063   \n",
       "4  0.214920 -0.087094  0.053155 -0.046394 -0.264762  0.115810  0.272997   \n",
       "\n",
       "         14        15        16  Class  \n",
       "0 -0.133225  0.149162  0.080341     17  \n",
       "1 -0.064037 -0.040096  0.147393     21  \n",
       "2  0.175715 -0.045392 -0.197643      9  \n",
       "3  0.020326 -0.067436 -0.050562     21  \n",
       "4 -0.048212  0.042004  0.002226      9  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=0.95) #95%이상의 분산을 설명력을 갖는 차원축소\n",
    "new_data2 = pca.fit_transform(data2_norm)\n",
    "data2_norm2 = pd.DataFrame(new_data2)\n",
    "data_norm = data2_norm2.merge(target.to_frame(),left_index=True, right_index = True)\n",
    "data_norm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>Class</th>\n",
       "      <th>ClassA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.240235</td>\n",
       "      <td>-1.169858</td>\n",
       "      <td>0.663074</td>\n",
       "      <td>0.019229</td>\n",
       "      <td>0.620195</td>\n",
       "      <td>-0.742148</td>\n",
       "      <td>0.348154</td>\n",
       "      <td>-0.373015</td>\n",
       "      <td>-0.075575</td>\n",
       "      <td>-0.128976</td>\n",
       "      <td>-0.275285</td>\n",
       "      <td>0.310400</td>\n",
       "      <td>0.193656</td>\n",
       "      <td>-0.047904</td>\n",
       "      <td>-0.133225</td>\n",
       "      <td>0.149162</td>\n",
       "      <td>0.080341</td>\n",
       "      <td>17</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.225106</td>\n",
       "      <td>-0.629123</td>\n",
       "      <td>-0.091924</td>\n",
       "      <td>-0.062670</td>\n",
       "      <td>-0.266067</td>\n",
       "      <td>0.186320</td>\n",
       "      <td>0.080216</td>\n",
       "      <td>-0.201968</td>\n",
       "      <td>0.101115</td>\n",
       "      <td>0.224332</td>\n",
       "      <td>0.061510</td>\n",
       "      <td>-0.096633</td>\n",
       "      <td>0.261985</td>\n",
       "      <td>-0.049817</td>\n",
       "      <td>-0.064037</td>\n",
       "      <td>-0.040096</td>\n",
       "      <td>0.147393</td>\n",
       "      <td>21</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.190383</td>\n",
       "      <td>-0.517377</td>\n",
       "      <td>-0.379907</td>\n",
       "      <td>0.399697</td>\n",
       "      <td>-0.603177</td>\n",
       "      <td>-0.109152</td>\n",
       "      <td>0.063760</td>\n",
       "      <td>-0.082697</td>\n",
       "      <td>0.496658</td>\n",
       "      <td>-0.146083</td>\n",
       "      <td>0.055157</td>\n",
       "      <td>-0.007380</td>\n",
       "      <td>-0.086956</td>\n",
       "      <td>0.069441</td>\n",
       "      <td>0.175715</td>\n",
       "      <td>-0.045392</td>\n",
       "      <td>-0.197643</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.363851</td>\n",
       "      <td>-0.501417</td>\n",
       "      <td>-0.156138</td>\n",
       "      <td>-0.177678</td>\n",
       "      <td>0.142810</td>\n",
       "      <td>-0.444388</td>\n",
       "      <td>-0.358293</td>\n",
       "      <td>0.082453</td>\n",
       "      <td>0.159960</td>\n",
       "      <td>-0.063044</td>\n",
       "      <td>0.104709</td>\n",
       "      <td>0.137652</td>\n",
       "      <td>-0.010886</td>\n",
       "      <td>0.114063</td>\n",
       "      <td>0.020326</td>\n",
       "      <td>-0.067436</td>\n",
       "      <td>-0.050562</td>\n",
       "      <td>21</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.802729</td>\n",
       "      <td>-0.378539</td>\n",
       "      <td>-0.345526</td>\n",
       "      <td>-0.114439</td>\n",
       "      <td>0.687051</td>\n",
       "      <td>-0.119308</td>\n",
       "      <td>0.034842</td>\n",
       "      <td>0.214920</td>\n",
       "      <td>-0.087094</td>\n",
       "      <td>0.053155</td>\n",
       "      <td>-0.046394</td>\n",
       "      <td>-0.264762</td>\n",
       "      <td>0.115810</td>\n",
       "      <td>0.272997</td>\n",
       "      <td>-0.048212</td>\n",
       "      <td>0.042004</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.240235 -1.169858  0.663074  0.019229  0.620195 -0.742148  0.348154   \n",
       "1 -0.225106 -0.629123 -0.091924 -0.062670 -0.266067  0.186320  0.080216   \n",
       "2 -0.190383 -0.517377 -0.379907  0.399697 -0.603177 -0.109152  0.063760   \n",
       "3 -0.363851 -0.501417 -0.156138 -0.177678  0.142810 -0.444388 -0.358293   \n",
       "4 -0.802729 -0.378539 -0.345526 -0.114439  0.687051 -0.119308  0.034842   \n",
       "\n",
       "          7         8         9        10        11        12        13  \\\n",
       "0 -0.373015 -0.075575 -0.128976 -0.275285  0.310400  0.193656 -0.047904   \n",
       "1 -0.201968  0.101115  0.224332  0.061510 -0.096633  0.261985 -0.049817   \n",
       "2 -0.082697  0.496658 -0.146083  0.055157 -0.007380 -0.086956  0.069441   \n",
       "3  0.082453  0.159960 -0.063044  0.104709  0.137652 -0.010886  0.114063   \n",
       "4  0.214920 -0.087094  0.053155 -0.046394 -0.264762  0.115810  0.272997   \n",
       "\n",
       "         14        15        16  Class  ClassA  \n",
       "0 -0.133225  0.149162  0.080341     17    17.0  \n",
       "1 -0.064037 -0.040096  0.147393     21    21.0  \n",
       "2  0.175715 -0.045392 -0.197643      9     9.0  \n",
       "3  0.020326 -0.067436 -0.050562     21    21.0  \n",
       "4 -0.048212  0.042004  0.002226      9     9.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def func(data_norm) :\n",
    "    if data_norm['Class'] == 9 or data_norm['Class'] == 21 or data_norm['Class'] == 17 \\\n",
    "    or data_norm['Class'] == 16 or data_norm['Class'] == 198 or data_norm['Class'] == 76 \\\n",
    "    or data_norm['Class'] == 22 :\n",
    "        return data_norm['Class']\n",
    "    else : return 200\n",
    "data_norm['ClassA'] = data_norm.apply(func, axis = 1)\n",
    "data_norm1 = data_norm[data_norm['ClassA'] != 200]\n",
    "\n",
    "data_norm1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "def func2(data_norm1) :\n",
    "    if data_norm1['Class'] == 9 : return 0\n",
    "    else : return 1\n",
    "data_norm1['ClassA'] = data_norm1.apply(func2, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_classes = pd.value_counts(data_norm1['ClassA'], sort = True)\n",
    "count_classes.plot(kind = 'bar', rot=0)\n",
    "plt.title(\"Transaction Class Distribution\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data_norm1.drop(['Class','ClassA'], axis=1)\n",
    "y= data_norm1['ClassA']\n",
    "\n",
    "train, test = train_test_split(data_norm1, test_size = 0.3)\n",
    "x_train = train.drop(['Class','ClassA'], axis=1)\n",
    "y_train = train['ClassA']\n",
    "x_test = test.drop(['Class','ClassA'], axis=1)\n",
    "y_test = test['ClassA']\n",
    "\n",
    "train2=train.drop('Class',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42,ratio='minority')\n",
    "x_train_sm, y_train_sm = smote.fit_sample(x_train, y_train)\n",
    "\n",
    "sns.countplot(y_train_sm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=x_test.values\n",
    "y_test=y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 540 out of 540 | elapsed: 394.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9028357286354505"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Random Forest classifier\n",
    "RFC = RandomForestClassifier()\n",
    "\n",
    "## Search grid for optimal parameters\n",
    "rf_param_grid = {\"max_depth\": [None],\n",
    "              \"max_features\": [3, 8, 8],\n",
    "              \"min_samples_split\": [2, 3, 8],\n",
    "              \"min_samples_leaf\": [1, 3, 8],\n",
    "              \"bootstrap\": [False],\n",
    "              \"n_estimators\" :[100,300],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "\n",
    "\n",
    "gsRFC = GridSearchCV(RFC, rf_param_grid, cv=k_fold, scoring=\"accuracy\",  verbose = 1)\n",
    "#print(score)\n",
    "\n",
    "gsRFC.fit(x_train_sm,y_train_sm)\n",
    "\n",
    "RFC_best = gsRFC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsRFC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   56.5s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=4)]: Done 720 out of 720 | elapsed: 17.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8770669139236594"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GBM classifier\n",
    "GBC = GradientBoostingClassifier()\n",
    "\n",
    "gb_param_grid = {'loss' : [\"deviance\"],\n",
    "              'n_estimators' : [100,200,300],\n",
    "              'learning_rate': [0.1, 0.05, 0.01],\n",
    "              'max_depth': [4, 8],\n",
    "              'min_samples_leaf': [100,150],\n",
    "              'max_features': [0.3, 0.1] \n",
    "              }\n",
    "\n",
    "gsGBC = GridSearchCV(GBC,param_grid = gb_param_grid, cv=k_fold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gsGBC.fit(x_train_sm,y_train_sm)\n",
    "\n",
    "GBC_best = gsGBC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsGBC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed: 31.8min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed: 146.7min\n",
      "[Parallel(n_jobs=4)]: Done 280 out of 280 | elapsed: 269.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8753283881934786"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### SVC classifier\n",
    "SVMC = SVC(probability=True)\n",
    "svc_param_grid = {'kernel': ['rbf'], \n",
    "                  'gamma': [ 0.001, 0.01, 0.1, 1],\n",
    "                  'C': [1, 10, 50, 100,200,300, 1000]}\n",
    "\n",
    "gsSVMC = GridSearchCV(SVMC,param_grid = svc_param_grid, cv=k_fold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gsSVMC.fit(x_train_sm,y_train_sm)\n",
    "\n",
    "SVMC_best = gsSVMC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsSVMC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 135 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed: 24.7min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed: 38.7min\n",
      "[Parallel(n_jobs=4)]: Done 1350 out of 1350 | elapsed: 42.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8621155926441044"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### XGboost classifier\n",
    "XGBC = XGBClassifier()\n",
    "xgb_param_grid = {'max_depth':[3,5,7],\n",
    "                  'min_child_weight':[3,5,6],\n",
    "                  'gamma': [ 0, 0.001, 0.01, 0.1, 1],\n",
    "                  'learning_rate':[0.1, 0.05, 0.01]}\n",
    "\n",
    "gsXGBC = GridSearchCV(XGBC,param_grid = xgb_param_grid, cv=k_fold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gsXGBC.fit(x_train_sm,y_train_sm)\n",
    "\n",
    "XGBC_best = gsXGBC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsXGBC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "votingC = VotingClassifier(estimators=[('rfc', RFC_best), \n",
    "('svc', SVMC_best),('gbc',GBC_best), ('xgb', XGBC_best)], voting='hard', n_jobs=4)\n",
    "\n",
    "votingC = votingC.fit(x_train_sm,y_train_sm)\n",
    "\n",
    "prediction = votingC.predict(x_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kim\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kim\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\kim\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['0 ', '1 ', '2 ', '3 ', '4 ', '5 ', '6 ', '7 ', '8 ', '9 ', '10', '11', '12', '13', '14', '15', '16'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16']\nexpected 9 , 3 , 4 , 1 , 0 , 12, 13, 11, 5 , 7 , 14, 16, 10, 6 , 8 , 15, 2  in input data\ntraining data did not have the following fields: f14, f1, f9, f7, f0, f6, f15, f2, f8, f11, f12, f13, f10, f16, f4, f3, f5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-3f66ee65bef0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# 성능\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mstack_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg_stack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# 예측모형 성능 비교\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mlxtend\\regressor\\stacking_regression.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    229\u001b[0m         \"\"\"\n\u001b[0;32m    230\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'regr_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[0mmeta_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_meta_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_features_in_secondary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mlxtend\\regressor\\stacking_regression.py\u001b[0m in \u001b[0;36mpredict_meta_features\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    212\u001b[0m         \"\"\"\n\u001b[0;32m    213\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'regr_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregr_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mlxtend\\regressor\\stacking_regression.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    212\u001b[0m         \"\"\"\n\u001b[0;32m    213\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'regr_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregr_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, validate_features)\u001b[0m\n\u001b[0;32m    789\u001b[0m                                                  \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m                                                  \u001b[0mntree_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m                                                  validate_features=validate_features)\n\u001b[0m\u001b[0;32m    792\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m             \u001b[1;31m# If output_margin is active, simply return the scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1283\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1284\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1286\u001b[0m         \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1689\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[1;32m-> 1690\u001b[1;33m                                             data.feature_names))\n\u001b[0m\u001b[0;32m   1691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1692\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['0 ', '1 ', '2 ', '3 ', '4 ', '5 ', '6 ', '7 ', '8 ', '9 ', '10', '11', '12', '13', '14', '15', '16'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16']\nexpected 9 , 3 , 4 , 1 , 0 , 12, 13, 11, 5 , 7 , 14, 16, 10, 6 , 8 , 15, 2  in input data\ntraining data did not have the following fields: f14, f1, f9, f7, f0, f6, f15, f2, f8, f11, f12, f13, f10, f16, f4, f3, f5"
     ]
    }
   ],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "\n",
    "# 예측모형 아키텍처\n",
    "## 첫번째 계층 회귀모형\n",
    "XGBC = XGBClassifier()\n",
    "SVMC = SVC(probability=True)\n",
    "RFC = RandomForestClassifier()\n",
    "\n",
    "## 두번째 계층 회귀모형\n",
    "reg_meta = RandomForestClassifier()\n",
    "\n",
    "# 스태킹 예측모형\n",
    "reg_stack = StackingRegressor(\n",
    "    regressors=[XGBC, SVMC, RFC],\n",
    "    meta_regressor=reg_meta,\n",
    "    use_features_in_secondary=True)\n",
    "reg_stack.fit(x_train, y_train)\n",
    "\n",
    "# 성능\n",
    "stack_pred = reg_stack.predict(x_test)\n",
    "\n",
    "# 예측모형 성능 비교\n",
    "reg_stack_rmse = np.sqrt(mean_squared_error(y_test, stack_pred))\n",
    "print(f'구글 앱 평점 예측 RMSE(Ensemble - Averaging): {reg_stack_rmse:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
