{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import os \n",
    "import warnings\n",
    "from patsy import dmatrices\n",
    "import statsmodels.api as sm;\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from pylab import rcParams\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from matplotlib import pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "import lightgbm as lgb\n",
    "import sklearn\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53692, 94)\n"
     ]
    }
   ],
   "source": [
    "#data = pd.read_csv('D:/FV_raw/S01_total_rev.csv')\n",
    "data = pd.read_csv('C:\\\\Users\\\\\\koreaw\\\\비즈니스어낼리틱스\\\\BA_data\\\\S01_data_rev_1.csv')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.704672</td>\n",
       "      <td>0.613381</td>\n",
       "      <td>0.602628</td>\n",
       "      <td>0.3787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.613485</td>\n",
       "      <td>0.826649</td>\n",
       "      <td>0.826649</td>\n",
       "      <td>0.6131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085121</td>\n",
       "      <td>0.036100</td>\n",
       "      <td>0.088404</td>\n",
       "      <td>0.135428</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>0.7236</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.276039</td>\n",
       "      <td>0.489615</td>\n",
       "      <td>0.488530</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.489699</td>\n",
       "      <td>0.556513</td>\n",
       "      <td>0.556513</td>\n",
       "      <td>0.3868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099081</td>\n",
       "      <td>0.023713</td>\n",
       "      <td>0.078263</td>\n",
       "      <td>0.139745</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.7902</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.180883</td>\n",
       "      <td>0.376915</td>\n",
       "      <td>0.429988</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.376979</td>\n",
       "      <td>0.512430</td>\n",
       "      <td>0.396420</td>\n",
       "      <td>0.3868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115764</td>\n",
       "      <td>0.156609</td>\n",
       "      <td>0.222002</td>\n",
       "      <td>0.141652</td>\n",
       "      <td>0.1174</td>\n",
       "      <td>0.2804</td>\n",
       "      <td>0.01976</td>\n",
       "      <td>0.023164</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.227390</td>\n",
       "      <td>0.416411</td>\n",
       "      <td>0.446834</td>\n",
       "      <td>0.7901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416482</td>\n",
       "      <td>0.512430</td>\n",
       "      <td>0.460225</td>\n",
       "      <td>0.3868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090398</td>\n",
       "      <td>0.067953</td>\n",
       "      <td>0.152116</td>\n",
       "      <td>0.118261</td>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.6053</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.161380</td>\n",
       "      <td>0.365169</td>\n",
       "      <td>0.429988</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.365231</td>\n",
       "      <td>0.460225</td>\n",
       "      <td>0.460225</td>\n",
       "      <td>0.3868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009193</td>\n",
       "      <td>0.017342</td>\n",
       "      <td>0.024471</td>\n",
       "      <td>0.115149</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.9704</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2       3    4         5         6         7  \\\n",
       "0  0.704672  0.613381  0.602628  0.3787  0.0  0.613485  0.826649  0.826649   \n",
       "1  0.276039  0.489615  0.488530  0.7500  0.0  0.489699  0.556513  0.556513   \n",
       "2  0.180883  0.376915  0.429988  0.7500  0.0  0.376979  0.512430  0.396420   \n",
       "3  0.227390  0.416411  0.446834  0.7901  0.0  0.416482  0.512430  0.460225   \n",
       "4  0.161380  0.365169  0.429988  0.6875  0.0  0.365231  0.460225  0.460225   \n",
       "\n",
       "        8    9  ...        79        80        81        82      83      84  \\\n",
       "0  0.6131  0.0  ...  0.085121  0.036100  0.088404  0.135428  0.0328  0.7236   \n",
       "1  0.3868  0.0  ...  0.099081  0.023713  0.078263  0.139745  0.0347  0.7902   \n",
       "2  0.3868  0.0  ...  0.115764  0.156609  0.222002  0.141652  0.1174  0.2804   \n",
       "3  0.3868  0.0  ...  0.090398  0.067953  0.152116  0.118261  0.0518  0.6053   \n",
       "4  0.3868  0.0  ...  0.009193  0.017342  0.024471  0.115149  0.0054  0.9704   \n",
       "\n",
       "        85        86   87  Class  \n",
       "0  0.00000  0.000000  0.5     17  \n",
       "1  0.00000  0.003934  1.0     21  \n",
       "2  0.01976  0.023164  1.0      9  \n",
       "3  0.00000  0.002404  1.0     21  \n",
       "4  0.00000  0.000000  0.5      9  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = data.drop(['L0t','Class','S_NO','D_ID','FV89','FV90'], axis=1)\n",
    "target = data['Class']\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "data2_norm=min_max_scaler.fit_transform(var)\n",
    "data2_norm = pd.DataFrame(data2_norm)\n",
    "data_norm = data2_norm.merge(target.to_frame(),left_index=True, right_index = True)\n",
    "data_norm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.130768</td>\n",
       "      <td>-1.038052</td>\n",
       "      <td>0.697290</td>\n",
       "      <td>0.165806</td>\n",
       "      <td>0.487045</td>\n",
       "      <td>0.896660</td>\n",
       "      <td>-0.127558</td>\n",
       "      <td>0.114706</td>\n",
       "      <td>0.154536</td>\n",
       "      <td>0.349317</td>\n",
       "      <td>0.264798</td>\n",
       "      <td>0.195927</td>\n",
       "      <td>0.076353</td>\n",
       "      <td>0.145501</td>\n",
       "      <td>-0.127520</td>\n",
       "      <td>-0.110704</td>\n",
       "      <td>0.127078</td>\n",
       "      <td>0.020761</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.249376</td>\n",
       "      <td>-0.617195</td>\n",
       "      <td>-0.025617</td>\n",
       "      <td>-0.003057</td>\n",
       "      <td>-0.323223</td>\n",
       "      <td>-0.159566</td>\n",
       "      <td>-0.084079</td>\n",
       "      <td>0.192891</td>\n",
       "      <td>0.120966</td>\n",
       "      <td>0.012226</td>\n",
       "      <td>-0.033878</td>\n",
       "      <td>-0.075836</td>\n",
       "      <td>0.219057</td>\n",
       "      <td>0.133422</td>\n",
       "      <td>0.037402</td>\n",
       "      <td>-0.105950</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.057020</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.269553</td>\n",
       "      <td>-0.492975</td>\n",
       "      <td>-0.262176</td>\n",
       "      <td>-0.183749</td>\n",
       "      <td>-0.594876</td>\n",
       "      <td>0.122842</td>\n",
       "      <td>-0.117533</td>\n",
       "      <td>0.290239</td>\n",
       "      <td>-0.408543</td>\n",
       "      <td>-0.068274</td>\n",
       "      <td>-0.084349</td>\n",
       "      <td>-0.002861</td>\n",
       "      <td>-0.122769</td>\n",
       "      <td>0.042745</td>\n",
       "      <td>-0.005036</td>\n",
       "      <td>0.147850</td>\n",
       "      <td>-0.101937</td>\n",
       "      <td>-0.093063</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.399706</td>\n",
       "      <td>-0.494862</td>\n",
       "      <td>-0.085869</td>\n",
       "      <td>-0.167540</td>\n",
       "      <td>0.414870</td>\n",
       "      <td>0.053105</td>\n",
       "      <td>-0.380552</td>\n",
       "      <td>0.034769</td>\n",
       "      <td>-0.154443</td>\n",
       "      <td>-0.006329</td>\n",
       "      <td>-0.109446</td>\n",
       "      <td>0.142629</td>\n",
       "      <td>-0.130427</td>\n",
       "      <td>0.049213</td>\n",
       "      <td>0.018222</td>\n",
       "      <td>-0.025605</td>\n",
       "      <td>-0.074968</td>\n",
       "      <td>-0.057281</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.791584</td>\n",
       "      <td>-0.367674</td>\n",
       "      <td>-0.300121</td>\n",
       "      <td>0.297141</td>\n",
       "      <td>0.648399</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.139348</td>\n",
       "      <td>-0.035591</td>\n",
       "      <td>0.070308</td>\n",
       "      <td>-0.099122</td>\n",
       "      <td>-0.016146</td>\n",
       "      <td>-0.236745</td>\n",
       "      <td>-0.078888</td>\n",
       "      <td>0.190031</td>\n",
       "      <td>0.224928</td>\n",
       "      <td>-0.088945</td>\n",
       "      <td>0.091973</td>\n",
       "      <td>-0.054262</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.130768 -1.038052  0.697290  0.165806  0.487045  0.896660 -0.127558   \n",
       "1 -0.249376 -0.617195 -0.025617 -0.003057 -0.323223 -0.159566 -0.084079   \n",
       "2 -0.269553 -0.492975 -0.262176 -0.183749 -0.594876  0.122842 -0.117533   \n",
       "3 -0.399706 -0.494862 -0.085869 -0.167540  0.414870  0.053105 -0.380552   \n",
       "4 -0.791584 -0.367674 -0.300121  0.297141  0.648399  0.088933  0.139348   \n",
       "\n",
       "          7         8         9        10        11        12        13  \\\n",
       "0  0.114706  0.154536  0.349317  0.264798  0.195927  0.076353  0.145501   \n",
       "1  0.192891  0.120966  0.012226 -0.033878 -0.075836  0.219057  0.133422   \n",
       "2  0.290239 -0.408543 -0.068274 -0.084349 -0.002861 -0.122769  0.042745   \n",
       "3  0.034769 -0.154443 -0.006329 -0.109446  0.142629 -0.130427  0.049213   \n",
       "4 -0.035591  0.070308 -0.099122 -0.016146 -0.236745 -0.078888  0.190031   \n",
       "\n",
       "         14        15        16        17  Class  \n",
       "0 -0.127520 -0.110704  0.127078  0.020761     17  \n",
       "1  0.037402 -0.105950  0.002519  0.057020     21  \n",
       "2 -0.005036  0.147850 -0.101937 -0.093063      9  \n",
       "3  0.018222 -0.025605 -0.074968 -0.057281     21  \n",
       "4  0.224928 -0.088945  0.091973 -0.054262      9  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=0.95) #95%이상의 분산을 설명력을 갖는 차원축소\n",
    "new_data2 = pca.fit_transform(data2_norm)\n",
    "data2_norm2 = pd.DataFrame(new_data2)\n",
    "data_norm = data2_norm2.merge(target.to_frame(),left_index=True, right_index = True)\n",
    "data_norm.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 7개, 최종 데이터 셋 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>Class</th>\n",
       "      <th>ClassA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.130768</td>\n",
       "      <td>-1.038052</td>\n",
       "      <td>0.697290</td>\n",
       "      <td>0.165806</td>\n",
       "      <td>0.487045</td>\n",
       "      <td>0.896660</td>\n",
       "      <td>-0.127558</td>\n",
       "      <td>0.114706</td>\n",
       "      <td>0.154536</td>\n",
       "      <td>0.349317</td>\n",
       "      <td>0.264798</td>\n",
       "      <td>0.195927</td>\n",
       "      <td>0.076353</td>\n",
       "      <td>0.145501</td>\n",
       "      <td>-0.127520</td>\n",
       "      <td>-0.110704</td>\n",
       "      <td>0.127078</td>\n",
       "      <td>0.020761</td>\n",
       "      <td>17</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.249376</td>\n",
       "      <td>-0.617195</td>\n",
       "      <td>-0.025617</td>\n",
       "      <td>-0.003057</td>\n",
       "      <td>-0.323223</td>\n",
       "      <td>-0.159566</td>\n",
       "      <td>-0.084079</td>\n",
       "      <td>0.192891</td>\n",
       "      <td>0.120966</td>\n",
       "      <td>0.012226</td>\n",
       "      <td>-0.033878</td>\n",
       "      <td>-0.075836</td>\n",
       "      <td>0.219057</td>\n",
       "      <td>0.133422</td>\n",
       "      <td>0.037402</td>\n",
       "      <td>-0.105950</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.057020</td>\n",
       "      <td>21</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.269553</td>\n",
       "      <td>-0.492975</td>\n",
       "      <td>-0.262176</td>\n",
       "      <td>-0.183749</td>\n",
       "      <td>-0.594876</td>\n",
       "      <td>0.122842</td>\n",
       "      <td>-0.117533</td>\n",
       "      <td>0.290239</td>\n",
       "      <td>-0.408543</td>\n",
       "      <td>-0.068274</td>\n",
       "      <td>-0.084349</td>\n",
       "      <td>-0.002861</td>\n",
       "      <td>-0.122769</td>\n",
       "      <td>0.042745</td>\n",
       "      <td>-0.005036</td>\n",
       "      <td>0.147850</td>\n",
       "      <td>-0.101937</td>\n",
       "      <td>-0.093063</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.399706</td>\n",
       "      <td>-0.494862</td>\n",
       "      <td>-0.085869</td>\n",
       "      <td>-0.167540</td>\n",
       "      <td>0.414870</td>\n",
       "      <td>0.053105</td>\n",
       "      <td>-0.380552</td>\n",
       "      <td>0.034769</td>\n",
       "      <td>-0.154443</td>\n",
       "      <td>-0.006329</td>\n",
       "      <td>-0.109446</td>\n",
       "      <td>0.142629</td>\n",
       "      <td>-0.130427</td>\n",
       "      <td>0.049213</td>\n",
       "      <td>0.018222</td>\n",
       "      <td>-0.025605</td>\n",
       "      <td>-0.074968</td>\n",
       "      <td>-0.057281</td>\n",
       "      <td>21</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.791584</td>\n",
       "      <td>-0.367674</td>\n",
       "      <td>-0.300121</td>\n",
       "      <td>0.297141</td>\n",
       "      <td>0.648399</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.139348</td>\n",
       "      <td>-0.035591</td>\n",
       "      <td>0.070308</td>\n",
       "      <td>-0.099122</td>\n",
       "      <td>-0.016146</td>\n",
       "      <td>-0.236745</td>\n",
       "      <td>-0.078888</td>\n",
       "      <td>0.190031</td>\n",
       "      <td>0.224928</td>\n",
       "      <td>-0.088945</td>\n",
       "      <td>0.091973</td>\n",
       "      <td>-0.054262</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.130768 -1.038052  0.697290  0.165806  0.487045  0.896660 -0.127558   \n",
       "1 -0.249376 -0.617195 -0.025617 -0.003057 -0.323223 -0.159566 -0.084079   \n",
       "2 -0.269553 -0.492975 -0.262176 -0.183749 -0.594876  0.122842 -0.117533   \n",
       "3 -0.399706 -0.494862 -0.085869 -0.167540  0.414870  0.053105 -0.380552   \n",
       "4 -0.791584 -0.367674 -0.300121  0.297141  0.648399  0.088933  0.139348   \n",
       "\n",
       "          7         8         9        10        11        12        13  \\\n",
       "0  0.114706  0.154536  0.349317  0.264798  0.195927  0.076353  0.145501   \n",
       "1  0.192891  0.120966  0.012226 -0.033878 -0.075836  0.219057  0.133422   \n",
       "2  0.290239 -0.408543 -0.068274 -0.084349 -0.002861 -0.122769  0.042745   \n",
       "3  0.034769 -0.154443 -0.006329 -0.109446  0.142629 -0.130427  0.049213   \n",
       "4 -0.035591  0.070308 -0.099122 -0.016146 -0.236745 -0.078888  0.190031   \n",
       "\n",
       "         14        15        16        17  Class  ClassA  \n",
       "0 -0.127520 -0.110704  0.127078  0.020761     17    17.0  \n",
       "1  0.037402 -0.105950  0.002519  0.057020     21    21.0  \n",
       "2 -0.005036  0.147850 -0.101937 -0.093063      9     9.0  \n",
       "3  0.018222 -0.025605 -0.074968 -0.057281     21    21.0  \n",
       "4  0.224928 -0.088945  0.091973 -0.054262      9     9.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def func(data_norm) :\n",
    "    if data_norm['Class'] == 9 or data_norm['Class'] == 21 or data_norm['Class'] == 17 \\\n",
    "    or data_norm['Class'] == 16 or data_norm['Class'] == 198 or data_norm['Class'] == 76 \\\n",
    "    or data_norm['Class'] == 22 :\n",
    "        return data_norm['Class']\n",
    "    else : return 200\n",
    "data_norm['ClassA'] = data_norm.apply(func, axis = 1)\n",
    "data_norm1 = data_norm[data_norm['ClassA'] != 200]\n",
    "\n",
    "data_norm1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 vs all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "def func(data_norm1) :\n",
    "    if data_norm1['Class'] == 9 : return 0\n",
    "    else : return 1\n",
    "data_norm1['ClassA'] = data_norm1.apply(func, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>Class</th>\n",
       "      <th>ClassA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.130768</td>\n",
       "      <td>-1.038052</td>\n",
       "      <td>0.697290</td>\n",
       "      <td>0.165806</td>\n",
       "      <td>0.487045</td>\n",
       "      <td>0.896660</td>\n",
       "      <td>-0.127558</td>\n",
       "      <td>0.114706</td>\n",
       "      <td>0.154536</td>\n",
       "      <td>0.349317</td>\n",
       "      <td>0.264798</td>\n",
       "      <td>0.195927</td>\n",
       "      <td>0.076353</td>\n",
       "      <td>0.145501</td>\n",
       "      <td>-0.127520</td>\n",
       "      <td>-0.110704</td>\n",
       "      <td>0.127078</td>\n",
       "      <td>0.020761</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.249376</td>\n",
       "      <td>-0.617195</td>\n",
       "      <td>-0.025617</td>\n",
       "      <td>-0.003057</td>\n",
       "      <td>-0.323223</td>\n",
       "      <td>-0.159566</td>\n",
       "      <td>-0.084079</td>\n",
       "      <td>0.192891</td>\n",
       "      <td>0.120966</td>\n",
       "      <td>0.012226</td>\n",
       "      <td>-0.033878</td>\n",
       "      <td>-0.075836</td>\n",
       "      <td>0.219057</td>\n",
       "      <td>0.133422</td>\n",
       "      <td>0.037402</td>\n",
       "      <td>-0.105950</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.057020</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.269553</td>\n",
       "      <td>-0.492975</td>\n",
       "      <td>-0.262176</td>\n",
       "      <td>-0.183749</td>\n",
       "      <td>-0.594876</td>\n",
       "      <td>0.122842</td>\n",
       "      <td>-0.117533</td>\n",
       "      <td>0.290239</td>\n",
       "      <td>-0.408543</td>\n",
       "      <td>-0.068274</td>\n",
       "      <td>-0.084349</td>\n",
       "      <td>-0.002861</td>\n",
       "      <td>-0.122769</td>\n",
       "      <td>0.042745</td>\n",
       "      <td>-0.005036</td>\n",
       "      <td>0.147850</td>\n",
       "      <td>-0.101937</td>\n",
       "      <td>-0.093063</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.399706</td>\n",
       "      <td>-0.494862</td>\n",
       "      <td>-0.085869</td>\n",
       "      <td>-0.167540</td>\n",
       "      <td>0.414870</td>\n",
       "      <td>0.053105</td>\n",
       "      <td>-0.380552</td>\n",
       "      <td>0.034769</td>\n",
       "      <td>-0.154443</td>\n",
       "      <td>-0.006329</td>\n",
       "      <td>-0.109446</td>\n",
       "      <td>0.142629</td>\n",
       "      <td>-0.130427</td>\n",
       "      <td>0.049213</td>\n",
       "      <td>0.018222</td>\n",
       "      <td>-0.025605</td>\n",
       "      <td>-0.074968</td>\n",
       "      <td>-0.057281</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.791584</td>\n",
       "      <td>-0.367674</td>\n",
       "      <td>-0.300121</td>\n",
       "      <td>0.297141</td>\n",
       "      <td>0.648399</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.139348</td>\n",
       "      <td>-0.035591</td>\n",
       "      <td>0.070308</td>\n",
       "      <td>-0.099122</td>\n",
       "      <td>-0.016146</td>\n",
       "      <td>-0.236745</td>\n",
       "      <td>-0.078888</td>\n",
       "      <td>0.190031</td>\n",
       "      <td>0.224928</td>\n",
       "      <td>-0.088945</td>\n",
       "      <td>0.091973</td>\n",
       "      <td>-0.054262</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.130768 -1.038052  0.697290  0.165806  0.487045  0.896660 -0.127558   \n",
       "1 -0.249376 -0.617195 -0.025617 -0.003057 -0.323223 -0.159566 -0.084079   \n",
       "2 -0.269553 -0.492975 -0.262176 -0.183749 -0.594876  0.122842 -0.117533   \n",
       "3 -0.399706 -0.494862 -0.085869 -0.167540  0.414870  0.053105 -0.380552   \n",
       "4 -0.791584 -0.367674 -0.300121  0.297141  0.648399  0.088933  0.139348   \n",
       "\n",
       "          7         8         9        10        11        12        13  \\\n",
       "0  0.114706  0.154536  0.349317  0.264798  0.195927  0.076353  0.145501   \n",
       "1  0.192891  0.120966  0.012226 -0.033878 -0.075836  0.219057  0.133422   \n",
       "2  0.290239 -0.408543 -0.068274 -0.084349 -0.002861 -0.122769  0.042745   \n",
       "3  0.034769 -0.154443 -0.006329 -0.109446  0.142629 -0.130427  0.049213   \n",
       "4 -0.035591  0.070308 -0.099122 -0.016146 -0.236745 -0.078888  0.190031   \n",
       "\n",
       "         14        15        16        17  Class  ClassA  \n",
       "0 -0.127520 -0.110704  0.127078  0.020761     17       1  \n",
       "1  0.037402 -0.105950  0.002519  0.057020     21       1  \n",
       "2 -0.005036  0.147850 -0.101937 -0.093063      9       0  \n",
       "3  0.018222 -0.025605 -0.074968 -0.057281     21       1  \n",
       "4  0.224928 -0.088945  0.091973 -0.054262      9       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_norm1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data_norm1.drop(['Class','ClassA'], axis=1)\n",
    "y= data_norm1['ClassA']\n",
    "\n",
    "train, test = train_test_split(data_norm1, test_size = 0.3)\n",
    "x_train = train.drop(['Class','ClassA'], axis=1)\n",
    "y_train = train['ClassA']\n",
    "x_test = test.drop(['Class','ClassA'], axis=1)\n",
    "y_test = test['ClassA']\n",
    "\n",
    "train2=train.drop('Class',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42,ratio='minority')\n",
    "x_train_sm, y_train_sm = smote.fit_sample(x_train, y_train)\n",
    "\n",
    "sns.countplot(y_train_sm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=x_test.values\n",
    "y_test=y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7981359399863606"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaBoost = AdaBoostClassifier(base_estimator=None,\n",
    "                              learning_rate=1.0,\n",
    "                              n_estimators=100)\n",
    "\n",
    "adaBoost.fit(x_train_sm, y_train_sm)\n",
    "\n",
    "y_pred = adaBoost.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.80      0.84      8877\n",
      "           1       0.66      0.80      0.72      4320\n",
      "\n",
      "    accuracy                           0.80     13197\n",
      "   macro avg       0.77      0.80      0.78     13197\n",
      "weighted avg       0.81      0.80      0.80     13197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the XGboost Model for Classification\n",
    "model1 = xgb.XGBClassifier()\n",
    "model2 = xgb.XGBClassifier(n_estimators=100, max_depth=8, learning_rate=0.1, subsample=0.5)\n",
    "\n",
    "train_model1 = model1.fit(x_train_sm, y_train_sm)\n",
    "train_model2 = model2.fit(x_train_sm, y_train_sm)\n",
    "\n",
    "\n",
    "pred1 = train_model1.predict(x_test)\n",
    "pred2 = train_model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87      8858\n",
      "           1       0.72      0.81      0.76      4339\n",
      "\n",
      "    accuracy                           0.83     13197\n",
      "   macro avg       0.81      0.83      0.82     13197\n",
      "weighted avg       0.84      0.83      0.84     13197\n",
      "\n",
      "------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89      8858\n",
      "           1       0.76      0.81      0.79      4339\n",
      "\n",
      "    accuracy                           0.85     13197\n",
      "   macro avg       0.83      0.84      0.84     13197\n",
      "weighted avg       0.86      0.85      0.86     13197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred1))\n",
    "print(\"------------------------------------------\")\n",
    "print(classification_report(y_test, pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 21 vs all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data_norm2 = data_norm1[data_norm1['ClassA']==1]\n",
    "\n",
    "def func(data_norm2) :\n",
    "    if data_norm2['Class'] == 21 : return 0\n",
    "    else : return 1\n",
    "data_norm2['ClassA'] = data_norm2.apply(func, axis = 1)\n",
    "\n",
    "train, test = train_test_split(data_norm2, test_size = 0.3)\n",
    "x_train = train.drop(['Class','ClassA'], axis=1)\n",
    "y_train = train['ClassA']\n",
    "x_test = test.drop(['Class','ClassA'], axis=1)\n",
    "y_test = test['ClassA']\n",
    "\n",
    "train2=train.drop('Class',axis=1)\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "ros = RandomUnderSampler(random_state=42)\n",
    "x_train_ros, y_train_ros = ros.fit_sample(x_train, y_train)\n",
    "\n",
    "smote = SMOTE(random_state=42,ratio='minority')\n",
    "x_train_sm, y_train_sm = smote.fit_sample(x_train, y_train)\n",
    "\n",
    "\n",
    "# sns.countplot(y_train_sm)\n",
    "# plt.show()\n",
    "\n",
    "x_test=x_test.values\n",
    "y_test=y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8478964401294499"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaBoost = AdaBoostClassifier(base_estimator=None,\n",
    "                              learning_rate=1.0,\n",
    "                              n_estimators=100)\n",
    "\n",
    "adaBoost.fit(x_train, y_train)\n",
    "\n",
    "y_pred = adaBoost.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7831715210355987"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaBoost = AdaBoostClassifier(base_estimator=None,\n",
    "                              learning_rate=1.0,\n",
    "                              n_estimators=100)\n",
    "\n",
    "adaBoost.fit(x_train_sm, y_train_sm)\n",
    "\n",
    "y_pred2 = adaBoost.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7746185852981969"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaBoost = AdaBoostClassifier(base_estimator=None,\n",
    "                              learning_rate=1.0,\n",
    "                              n_estimators=100)\n",
    "\n",
    "adaBoost.fit(x_train_ros, y_train_ros)\n",
    "\n",
    "y_pred3 = adaBoost.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.53      0.60       948\n",
      "           1       0.88      0.94      0.91      3378\n",
      "\n",
      "    accuracy                           0.85      4326\n",
      "   macro avg       0.79      0.73      0.76      4326\n",
      "weighted avg       0.84      0.85      0.84      4326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.73      0.61      1002\n",
      "           1       0.91      0.80      0.85      3324\n",
      "\n",
      "    accuracy                           0.78      4326\n",
      "   macro avg       0.72      0.76      0.73      4326\n",
      "weighted avg       0.82      0.78      0.79      4326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.76      0.61      1002\n",
      "           1       0.92      0.78      0.84      3324\n",
      "\n",
      "    accuracy                           0.77      4326\n",
      "   macro avg       0.71      0.77      0.73      4326\n",
      "weighted avg       0.82      0.77      0.79      4326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the XGboost Model for Classification\n",
    "model1 = xgb.XGBClassifier()\n",
    "model2 = xgb.XGBClassifier(n_estimators=100, max_depth=8, learning_rate=0.1, subsample=0.5)\n",
    "\n",
    "train_model1 = model1.fit(x_train_sm, y_train_sm)\n",
    "train_model2 = model2.fit(x_train_sm, y_train_sm)\n",
    "\n",
    "\n",
    "pred1 = train_model1.predict(x_test)\n",
    "pred2 = train_model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.75      0.67      1002\n",
      "           1       0.92      0.85      0.88      3324\n",
      "\n",
      "    accuracy                           0.83      4326\n",
      "   macro avg       0.76      0.80      0.78      4326\n",
      "weighted avg       0.85      0.83      0.83      4326\n",
      "\n",
      "------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69      1002\n",
      "           1       0.91      0.90      0.90      3324\n",
      "\n",
      "    accuracy                           0.85      4326\n",
      "   macro avg       0.79      0.80      0.80      4326\n",
      "weighted avg       0.86      0.85      0.85      4326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred1))\n",
    "print(\"------------------------------------------\")\n",
    "print(classification_report(y_test, pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class 17 vs all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_norm3 = data_norm2[data_norm2['ClassA']==1]\n",
    "\n",
    "def func(data_norm3) :\n",
    "    if data_norm3['Class'] == 17 : return 0\n",
    "    else : return 1\n",
    "data_norm3['ClassA'] = data_norm3.apply(func, axis = 1)\n",
    "\n",
    "train, test = train_test_split(data_norm3, test_size = 0.3)\n",
    "x_train = train.drop(['Class','ClassA'], axis=1)\n",
    "y_train = train['ClassA']\n",
    "x_test = test.drop(['Class','ClassA'], axis=1)\n",
    "y_test = test['ClassA']\n",
    "\n",
    "train2=train.drop('Class',axis=1)\n",
    "\n",
    "smote = SMOTE(random_state=42,ratio='minority')\n",
    "x_train_sm, y_train_sm = smote.fit_sample(x_train, y_train)\n",
    "\n",
    "sns.countplot(y_train_sm)\n",
    "plt.show()\n",
    "\n",
    "x_test=x_test.values\n",
    "y_test=y_test.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6617997616209773"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaBoost = AdaBoostClassifier(base_estimator=None,\n",
    "                              learning_rate=1.0,\n",
    "                              n_estimators=100)\n",
    "\n",
    "adaBoost.fit(x_train_sm, y_train_sm)\n",
    "\n",
    "y_pred = adaBoost.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.66      0.52       938\n",
      "           1       0.83      0.66      0.74      2418\n",
      "\n",
      "    accuracy                           0.66      3356\n",
      "   macro avg       0.63      0.66      0.63      3356\n",
      "weighted avg       0.72      0.66      0.68      3356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the XGboost Model for Classification\n",
    "model1 = xgb.XGBClassifier()\n",
    "model2 = xgb.XGBClassifier(n_estimators=100, max_depth=8, learning_rate=0.1, subsample=0.5)\n",
    "\n",
    "train_model1 = model1.fit(x_train_sm, y_train_sm)\n",
    "train_model2 = model2.fit(x_train_sm, y_train_sm)\n",
    "\n",
    "\n",
    "pred1 = train_model1.predict(x_test)\n",
    "pred2 = train_model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.74      0.57       938\n",
      "           1       0.87      0.67      0.76      2418\n",
      "\n",
      "    accuracy                           0.69      3356\n",
      "   macro avg       0.67      0.71      0.67      3356\n",
      "weighted avg       0.76      0.69      0.71      3356\n",
      "\n",
      "------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.64      0.58       938\n",
      "           1       0.85      0.77      0.81      2418\n",
      "\n",
      "    accuracy                           0.74      3356\n",
      "   macro avg       0.69      0.71      0.69      3356\n",
      "weighted avg       0.76      0.74      0.74      3356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred1))\n",
    "print(\"------------------------------------------\")\n",
    "print(classification_report(y_test, pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class 16 vs all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_norm4 = data_norm3[data_norm3['ClassA']==1]\n",
    "\n",
    "def func(data_norm4) :\n",
    "    if data_norm4['Class'] == 16 : return 0\n",
    "    else : return 1\n",
    "data_norm4['ClassA'] = data_norm4.apply(func, axis = 1)\n",
    "\n",
    "train, test = train_test_split(data_norm4, test_size = 0.3)\n",
    "x_train = train.drop(['Class','ClassA'], axis=1)\n",
    "y_train = train['ClassA']\n",
    "x_test = test.drop(['Class','ClassA'], axis=1)\n",
    "y_test = test['ClassA']\n",
    "\n",
    "train2=train.drop('Class',axis=1)\n",
    "\n",
    "smote = SMOTE(random_state=42,ratio='minority')\n",
    "x_train_sm, y_train_sm = smote.fit_sample(x_train, y_train)\n",
    "\n",
    "sns.countplot(y_train_sm)\n",
    "plt.show()\n",
    "\n",
    "x_test=x_test.values\n",
    "y_test=y_test.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7356130108423686"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaBoost = AdaBoostClassifier(base_estimator=None,\n",
    "                              learning_rate=1.0,\n",
    "                              n_estimators=100)\n",
    "\n",
    "adaBoost.fit(x_train_sm, y_train_sm)\n",
    "\n",
    "y_pred = adaBoost.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.75      0.63       721\n",
      "           1       0.87      0.73      0.79      1677\n",
      "\n",
      "    accuracy                           0.74      2398\n",
      "   macro avg       0.71      0.74      0.71      2398\n",
      "weighted avg       0.77      0.74      0.75      2398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the XGboost Model for Classification\n",
    "model1 = xgb.XGBClassifier()\n",
    "model2 = xgb.XGBClassifier(n_estimators=100, max_depth=8, learning_rate=0.1, subsample=0.5)\n",
    "\n",
    "train_model1 = model1.fit(x_train_sm, y_train_sm)\n",
    "train_model2 = model2.fit(x_train_sm, y_train_sm)\n",
    "\n",
    "\n",
    "pred1 = train_model1.predict(x_test)\n",
    "pred2 = train_model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.81      0.66       721\n",
      "           1       0.90      0.73      0.80      1677\n",
      "\n",
      "    accuracy                           0.75      2398\n",
      "   macro avg       0.73      0.77      0.73      2398\n",
      "weighted avg       0.80      0.75      0.76      2398\n",
      "\n",
      "------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.72      0.68       721\n",
      "           1       0.87      0.83      0.85      1677\n",
      "\n",
      "    accuracy                           0.79      2398\n",
      "   macro avg       0.76      0.77      0.76      2398\n",
      "weighted avg       0.80      0.79      0.80      2398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred1))\n",
    "print(\"------------------------------------------\")\n",
    "print(classification_report(y_test, pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 198 vs all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_norm5 = data_norm4[data_norm4['ClassA']==1]\n",
    "\n",
    "def func(data_norm5) :\n",
    "    if data_norm5['Class'] == 198 : return 0\n",
    "    else : return 1\n",
    "data_norm5['ClassA'] = data_norm5.apply(func, axis = 1)\n",
    "\n",
    "train, test = train_test_split(data_norm5, test_size = 0.3)\n",
    "x_train = train.drop(['Class','ClassA'], axis=1)\n",
    "y_train = train['ClassA']\n",
    "x_test = test.drop(['Class','ClassA'], axis=1)\n",
    "y_test = test['ClassA']\n",
    "\n",
    "train2=train.drop('Class',axis=1)\n",
    "\n",
    "smote = SMOTE(random_state=42,ratio='minority')\n",
    "x_train_sm, y_train_sm = smote.fit_sample(x_train, y_train)\n",
    "\n",
    "sns.countplot(y_train_sm)\n",
    "plt.show()\n",
    "\n",
    "x_test=x_test.values\n",
    "y_test=y_test.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9861861861861861"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaBoost = AdaBoostClassifier(base_estimator=None,\n",
    "                              learning_rate=1.0,\n",
    "                              n_estimators=100)\n",
    "\n",
    "adaBoost.fit(x_train_sm, y_train_sm)\n",
    "\n",
    "y_pred = adaBoost.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       622\n",
      "           1       0.99      0.99      0.99      1043\n",
      "\n",
      "    accuracy                           0.99      1665\n",
      "   macro avg       0.99      0.99      0.99      1665\n",
      "weighted avg       0.99      0.99      0.99      1665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the XGboost Model for Classification\n",
    "model1 = xgb.XGBClassifier()\n",
    "model2 = xgb.XGBClassifier(n_estimators=100, max_depth=8, learning_rate=0.1, subsample=0.5)\n",
    "\n",
    "train_model1 = model1.fit(x_train_sm, y_train_sm)\n",
    "train_model2 = model2.fit(x_train_sm, y_train_sm)\n",
    "\n",
    "\n",
    "pred1 = train_model1.predict(x_test)\n",
    "pred2 = train_model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       622\n",
      "           1       0.99      0.99      0.99      1043\n",
      "\n",
      "    accuracy                           0.99      1665\n",
      "   macro avg       0.99      0.99      0.99      1665\n",
      "weighted avg       0.99      0.99      0.99      1665\n",
      "\n",
      "------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       622\n",
      "           1       0.99      0.99      0.99      1043\n",
      "\n",
      "    accuracy                           0.99      1665\n",
      "   macro avg       0.99      0.99      0.99      1665\n",
      "weighted avg       0.99      0.99      0.99      1665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred1))\n",
    "print(\"------------------------------------------\")\n",
    "print(classification_report(y_test, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_2\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_norm6 = data_norm5[data_norm5['ClassA']==1]\n",
    "\n",
    "def func(data_norm6) :\n",
    "    if data_norm6['Class'] == 76 : return 0\n",
    "    else : return 1\n",
    "data_norm6['ClassA'] = data_norm6.apply(func, axis = 1)\n",
    "\n",
    "train, test = train_test_split(data_norm6, test_size = 0.3)\n",
    "x_train = train.drop(['Class','ClassA'], axis=1)\n",
    "y_train = train['ClassA']\n",
    "x_test = test.drop(['Class','ClassA'], axis=1)\n",
    "y_test = test['ClassA']\n",
    "\n",
    "train2=train.drop('Class',axis=1)\n",
    "\n",
    "smote = SMOTE(random_state=42,ratio='minority')\n",
    "x_train_sm, y_train_sm = smote.fit_sample(x_train, y_train)\n",
    "\n",
    "sns.countplot(y_train_sm)\n",
    "plt.show()\n",
    "\n",
    "x_test=x_test.values\n",
    "y_test=y_test.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8725023786869648"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaBoost = AdaBoostClassifier(base_estimator=None,\n",
    "                              learning_rate=1.0,\n",
    "                              n_estimators=100)\n",
    "\n",
    "adaBoost.fit(x_train_sm, y_train_sm)\n",
    "\n",
    "y_pred = adaBoost.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87       532\n",
      "           1       0.87      0.88      0.87       519\n",
      "\n",
      "    accuracy                           0.87      1051\n",
      "   macro avg       0.87      0.87      0.87      1051\n",
      "weighted avg       0.87      0.87      0.87      1051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the XGboost Model for Classification\n",
    "model1 = xgb.XGBClassifier()\n",
    "model2 = xgb.XGBClassifier(n_estimators=100, max_depth=8, learning_rate=0.1, subsample=0.5)\n",
    "\n",
    "train_model1 = model1.fit(x_train_sm, y_train_sm)\n",
    "train_model2 = model2.fit(x_train_sm, y_train_sm)\n",
    "\n",
    "\n",
    "pred1 = train_model1.predict(x_test)\n",
    "pred2 = train_model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       532\n",
      "           1       0.89      0.89      0.89       519\n",
      "\n",
      "    accuracy                           0.89      1051\n",
      "   macro avg       0.89      0.89      0.89      1051\n",
      "weighted avg       0.89      0.89      0.89      1051\n",
      "\n",
      "------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       532\n",
      "           1       0.89      0.89      0.89       519\n",
      "\n",
      "    accuracy                           0.89      1051\n",
      "   macro avg       0.89      0.89      0.89      1051\n",
      "weighted avg       0.89      0.89      0.89      1051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred1))\n",
    "print(\"------------------------------------------\")\n",
    "print(classification_report(y_test, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow_GPU",
   "language": "python",
   "name": "tf_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
